# 爬虫

## 概论：

### 什么是爬虫：

通过编写程序，模拟浏览器上网，然后让其去互联网上抓取数据的过程。

### http协议&https协议

#### 概念

http：服务器和客户端进行数据交互的一种形式

https：安全的超文本传输协议

#### 头信息

##### 请求

1. User-Agent：请求载体的身份标识，这个载体可以是一个电脑的浏览器，也可是一个爬虫
2. Connection：请求成功之后，是断开连接还是保持连接

##### 相应

1. Content-type：服务器响应回客户端的数据类型

## requests模块

模拟浏览器发送请求，指定url，然后发起请求，获取响应数据，数据存储

### 使用demo

1. [爬取文件的案例](./demo_py/requests_test.py)爬取了搜狗首页的数据

2. 采用UA伪装

3. 使用爬虫爬取百度翻译结果

   （这个的实现是由特殊性的，百度翻译的输入框每次输入都会发送一个请求，然后讲得到的翻译信息返回，这昂就方便我们通过浏览器抓包工具找寻翻译结果,最后发现这个东西是出现在aug里面，然后选择新版本的aug，设定程url，然后就是处理数据显示的类型，方便人阅读

4. 爬取豆瓣的官网的评论信息：

   这个demo，没有什么实质性的多的内容，就是要善于发现浏览器什么时候发送请求，这里是滚轮在刷新的时候进行请求，然后就可以直接使用requests去访问就可，上面给的是get就用`requests.get()`上面写的是post就用`requests.post()`然后别忘记使用UA伪装，还有`param`这个字典，就是把url问好”？“之后的内容写道字典里就可以了